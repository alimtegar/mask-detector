[{"/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/reportWebVitals.js":"1","/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/App.js":"2","/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/index.js":"3"},{"size":362,"mtime":1606491684339,"results":"4","hashOfConfig":"5"},{"size":6269,"mtime":1606568226939,"results":"6","hashOfConfig":"5"},{"size":500,"mtime":1606491684337,"results":"7","hashOfConfig":"5"},{"filePath":"8","messages":"9","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"s1o5zh",{"filePath":"10","messages":"11","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"12"},{"filePath":"13","messages":"14","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/reportWebVitals.js",[],"/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/App.js",["15","16"],"\nimport { useEffect, useRef } from 'react';\nimport * as faceapi from 'face-api.js';\nimport * as tf from '@tensorflow/tfjs';\n\n// Import video\n// import Video from './assets/videos/video.mp4';\n\n// Import styles\nimport './App.css';\n\nfunction App() {\n  const VIDEO_WIDTH = 480;\n  const VIDEO_HEIGHT = 360;\n  const FACE_API_MODELS_URI = '/models/face-api-models';\n  const MASK_DETECTOR_MODEL_URI = '/models/mask-detector-model/model.json';\n\n  // Refs\n  const videoRef = useRef();\n  const canvasRef = useRef();\n  const tmpCanvasRef = useRef();\n\n  useEffect(() => {\n    const webCamPromise = navigator.mediaDevices\n      .getUserMedia({\n        audio: false,\n        video: {\n          // Prevent different size between video and canvas\n          width: VIDEO_WIDTH,\n          height: VIDEO_HEIGHT,\n        },\n      })\n      .then((stream) => {\n        window.stream = stream;\n        videoRef.current.srcObject = stream;\n\n        return new Promise((resolve, _) => {\n          videoRef.current.onloadedmetadata = () => {\n            resolve();\n          };\n        });\n      });\n    const faceapiModelPromise = faceapi.nets.ssdMobilenetv1.loadFromUri(FACE_API_MODELS_URI);\n    const maskDetectorModelPromise = tf.loadLayersModel(MASK_DETECTOR_MODEL_URI);\n\n    console.log('Webcam and models are loading');\n\n    Promise.all([\n      webCamPromise,\n      faceapiModelPromise,\n      maskDetectorModelPromise,\n    ])\n      .then((result) => {\n        const _maskDetectorModel = result[2];\n\n        console.log('Webcam and models are loaded');\n        // console.log('mask detector model from promise', _maskDetectorModel);\n\n        detect(_maskDetectorModel);\n      })\n      .catch((error) => {\n        console.log(error);\n      });\n  }, []);\n\n  const detect = (maskDetectorModel) => {\n    faceapi.detectAllFaces(videoRef.current)\n      .then((faceDetections) => {\n        renderDetectionBox(faceDetections, maskDetectorModel);\n        // setTimeout(() => { detect(maskDetectorModel); }, 1000);\n        requestAnimationFrame(() => {\n          // console.log('maskDetectorModel from animation', maskDetectorModel);\n          detect(maskDetectorModel);\n        });\n      });\n  };\n\n  const renderDetectionBox = (faceDetections, maskDetectorModel) => {\n    const ctx = canvasRef.current.getContext('2d');\n    const tmpCtx = tmpCanvasRef.current.getContext('2d');\n\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n\n    // Font options\n    const font = \"16px sans-serif\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    faceDetections.map((faceDetection) => {\n      if (faceDetection) {\n        console.log('A face is detected');\n\n        const x = faceDetection.box._x;\n        const y = faceDetection.box._y;\n        const w = faceDetection.box._width;\n        const h = faceDetection.box._height;\n\n        // Crop video frame\n        tmpCtx.clearRect(0, 0, tmpCtx.canvas.width, tmpCtx.canvas.height);\n        tmpCtx.drawImage(\n          videoRef.current,\n          x, // x coordinate where to start cropping the frame\n          y, // y coordinate where to start cropping the frame\n          w, // w (width) of the cropped frame\n          h, // h (height) of the cropped frame\n          0, // x coordinate where to start placing the cropped frame\n          0, // y coordinate where to start placing the cropped frame\n          w, // w (width) of the cropped frame\n          h  // h (height) of the cropped frame\n        );\n\n        predict(maskDetectorModel)\n          .then((prediction) => {\n            let [withMask, withoutMask] = prediction;\n\n            // Tresholding the prediction\n            const treshold = 0.25;\n\n            withMask -= treshold;\n            withoutMask += treshold;\n\n            console.log('withMask', withMask);\n            console.log('withoutMask', withoutMask);\n            console.log();\n\n            // Draw the box\n            const color = withMask > withoutMask ? '#00FF00' : '#FF0000';\n\n            ctx.strokeStyle = color;\n            ctx.lineWidth = 2;\n            ctx.strokeRect(x, y, w, h);\n\n            // Draw the label \n            const label = withMask > withoutMask ? 'masked' : 'not masked';\n\n            ctx.fillStyle = color;\n\n            const textWidth = ctx.measureText(label).width;\n            const textHeight = parseInt(font, 10);\n\n            ctx.fillRect(x - 1, y - (textHeight + 4), textWidth + 4, textHeight + 4);\n\n            ctx.fillStyle = \"#000000\";\n            ctx.fillText(label, x, y - textHeight);\n          });\n      }\n    });\n  };\n\n  const predict = (maskDetectorModel) => {\n    // const is_new_od_model = maskDetectorModel.inputs.length === 3;\n\n    // const input_size = maskDetectorModel.inputs[0].shape[1];\n    // let inputs = tf.browser.fromPixels(tmpCanvasRef.current, 3);\n    // console.log('inputs', inputs);\n    // inputs = tf.image.resizeBilinear(inputs.expandDims().toFloat(), [input_size, input_size]);\n    // if (is_new_od_model) {\n    //   console.log(\"Object Detection Model V2 detected.\");\n    //   inputs = is_new_od_model ? inputs : inputs.reverse(-1); // RGB->BGR for old models\n    // }\n\n    // Preprocessing image\n    let image = tf.browser.fromPixels(tmpCanvasRef.current);\n    image = tf.image.resizeBilinear(image, [224, 224]);\n    image = tf.cast(image, 'float32');\n    image = tf.tensor4d(Array.from(image.dataSync()), [1, 224, 224, 3])\n\n    // console.log('image', image);\n    // console.log('maskDetectorModel', maskDetectorModel);\n\n    return maskDetectorModel.predict(image, { batchSize: 32 }).data();\n    // return new Promise((resolve) => resolve([0, 0]));\n  }\n\n  return (\n    <div className=\"App\">\n      <div id=\"preview\">\n        <video\n          className=\"fixed\"\n          autoPlay\n          playsInline\n          muted\n          width={VIDEO_WIDTH}\n          height={VIDEO_HEIGHT}\n          ref={videoRef}\n        // src={Video}\n        // type=\"video/mp4\"\n        // loop\n        />\n        <canvas\n          className=\"fixed\"\n          width={VIDEO_WIDTH}\n          height={VIDEO_HEIGHT}\n          ref={canvasRef}\n        />\n\n      </div>\n      <canvas\n        ref={tmpCanvasRef}\n        width={VIDEO_HEIGHT / 2}\n        height={VIDEO_HEIGHT}\n        style={{ position: 'absolute', left: 0, top: 0 }}\n      />\n    </div>\n  );\n}\n\nexport default App;\n","/Users/admin/Documents/Projects/real-time-mask-detector-v2/src/index.js",[],{"ruleId":"17","severity":1,"message":"18","line":64,"column":6,"nodeType":"19","endLine":64,"endColumn":8,"suggestions":"20"},{"ruleId":"21","severity":1,"message":"22","line":89,"column":40,"nodeType":"23","messageId":"24","endLine":89,"endColumn":42},"react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'detect'. Either include it or remove the dependency array.","ArrayExpression",["25"],"array-callback-return","Array.prototype.map() expects a return value from arrow function.","ArrowFunctionExpression","expectedInside",{"desc":"26","fix":"27"},"Update the dependencies array to be: [detect]",{"range":"28","text":"29"},[1727,1729],"[detect]"]